{
  "cells": [
    {
      "cell_type": "markdown",
      "id": 3.0293430767166755e+38,
      "metadata": {
        "id": 3.0293430767166755e+38
      },
      "source": [
        "# Gradio Demo: video_identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": 2.7299665331067346e+38,
      "metadata": {
        "id": 2.7299665331067346e+38,
        "outputId": "c74409ea-3535-44da-f7ec-be133b708f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio transformers onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": 2.8891853944186117e+38,
      "metadata": {
        "id": 2.8891853944186117e+38
      },
      "outputs": [],
      "source": [
        "# Downloading files from the demo repo\n",
        "import os\n",
        "os.mkdir('video')\n",
        "!wget -q -O video/video_sample.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_identity/video/video_sample.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": 4.438057757052328e+37,
      "metadata": {
        "id": 4.438057757052328e+37,
        "outputId": "4d813d10-c58f-4a43-c3d2-f3678cda6f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:319: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7866, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import onnxruntime\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import os\n",
        "import subprocess\n",
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "### --- Audio/Video to txt ---###\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipeline(\"automatic-speech-recognition\", \n",
        "                    model=\"openai/whisper-base.en\",\n",
        "                    chunk_length_s=30, device=device)\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
        "     \n",
        "\n",
        "def video_identity(video):\n",
        "    transcription = pipe(video)[\"text\"]\n",
        "    return transcription\n",
        "\n",
        "def summary(text):\n",
        "    text = text.split('.')\n",
        "    max_chunk = 500\n",
        "    current_chunk = 0\n",
        "    chunks = []\n",
        "    \n",
        "    \n",
        "    for t in text:\n",
        "        if len(chunks) == current_chunk + 1:\n",
        "            if len(chunks[current_chunk]) + len(t.split(' ')) <= max_chunk:\n",
        "                chunks[current_chunk].extend(t.split(' '))\n",
        "            else:\n",
        "                current_chunk += 1\n",
        "                chunks.append(t.split(' '))\n",
        "        else:\n",
        "          chunks.append(t.split(' '))\n",
        "    \n",
        "    for chunk in range(len(chunks)):\n",
        "        chunks[chunk] =' '.join(chunks[chunk])\n",
        "    \n",
        "    summ = summarizer(chunks,max_length = 100)\n",
        "\n",
        "    return summ\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "token  = AutoTokenizer.from_pretrained('distilroberta-base')\n",
        "\n",
        "inf_session = onnxruntime.InferenceSession('/content/drive/MyDrive/classifier1-quantized.onnx')\n",
        "input_name = inf_session.get_inputs()[0].name\n",
        "output_name = inf_session.get_outputs()[0].name\n",
        "\n",
        "classes = ['Art', 'Astrology', 'Biology', 'Chemistry', 'Economics', 'History', 'Literature', 'Philosophy', 'Physics', 'Politics', 'Psychology', 'Sociology']\n",
        "\n",
        "def classify(vid):\n",
        "    full_text = video_identity(vid)\n",
        "    sum = summary(full_text)[0]['summary_text']\n",
        "\n",
        "    \n",
        "    input_ids = token(sum)['input_ids'][:512]\n",
        "    logits = inf_session.run([output_name],{input_name : [input_ids]})[0]\n",
        "    logits = torch.FloatTensor(logits)\n",
        "    probs = torch.sigmoid(logits)[0]\n",
        "    return full_text, sum, dict(zip(classes,map(float,probs)))\n",
        "\n",
        "# label = gr.outputs.Label(num_top_classes=5)\n",
        "iface = gr.Interface(fn=classify,\n",
        "                     inputs=gr.inputs.Audio(source=\"upload\", type=\"filepath\"),\n",
        "                     outputs = ['text','text',gr.outputs.Label(num_top_classes=3)])\n",
        "\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "w4H4vV8hNQ6E",
        "outputId": "5423ee5f-b9d7-4e45-b159-af29b2b26dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "w4H4vV8hNQ6E",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}